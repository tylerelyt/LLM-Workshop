---
layout: default
title: Context Engineering
nav_order: 5
has_children: true
description: "Context management and optimization strategies for AI agents"
---

# Context Engineering
{: .no_toc }

æ¢ç´¢ AI æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å·¥ç¨‹è‰ºæœ¯ä¸ç§‘å­¦ï¼Œå­¦ä¹ é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥æ„å»ºé«˜æ€§èƒ½ã€å¯é çš„ç”Ÿäº§çº§æ™ºèƒ½ä½“ç³»ç»Ÿã€‚
{: .fs-6 .fw-300 }

## ç›®å½•
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## ç« èŠ‚æ¦‚è§ˆ

> "å¦‚æœæ¨¡å‹è¿›æ­¥æ˜¯æ¶¨æ½®ï¼Œæˆ‘ä»¬å¸Œæœ›æ™ºèƒ½ä½“æ˜¯èˆ¹ï¼Œè€Œéé’‰åœ¨æµ·åºŠä¸Šçš„æŸ±å­ã€‚"

æœ¬ç« æ¢è®¨ä¸Šä¸‹æ–‡å·¥ç¨‹çš„æ ¸å¿ƒç†å¿µå’Œæœ€ä½³å®è·µï¼Œè¿™äº›ç»éªŒæ¥è‡ªäºè¿­ä»£æ™ºèƒ½ä½“æ¡†æ¶å¼€å‘ä¸­çš„å®è·µæ¢ç´¢ã€‚

### æ ¸å¿ƒæ¨¡å—

âš¡ **KV-Cache ä¼˜åŒ–**
{: .label .label-blue }
ç¼“å­˜å‹å¥½çš„ prompt è®¾è®¡ï¼Œæˆæœ¬é™ä½ 90%
{: .fs-3 }

ğŸ¯ **å·¥å…·é®è”½ç­–ç•¥**
{: .label .label-green }
"é®è”½è€Œéç§»é™¤"åŸåˆ™ï¼Œä¿æŒç¼“å­˜æ•ˆç‡
{: .fs-3 }

ğŸ’¾ **æ–‡ä»¶ç³»ç»Ÿå†…å­˜**
{: .label .label-purple }
æ— é™å®¹é‡çš„æŒä¹…åŒ–å¤–éƒ¨å†…å­˜
{: .fs-3 }

ğŸ” **æ³¨æ„åŠ›å¤è¿°**
{: .label .label-yellow }
é€šè¿‡å¤è¿°å¼•å¯¼æ³¨æ„åŠ›åˆ†å¸ƒ
{: .fs-3 }

ğŸ› ï¸ **é”™è¯¯ä¿ç•™å­¦ä¹ **
{: .label .label-red }
"ä¿ç•™é”™è¯¯ä¿¡æ¯"ï¼Œä»å¤±è´¥ä¸­å­¦ä¹ 
{: .fs-3 }

---

## æ ¸å¿ƒå“²å­¦

### ä¸ºä»€ä¹ˆé€‰æ‹©ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Ÿ

**åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„æ™ºèƒ½ä½“æ¶æ„** vs **ç«¯åˆ°ç«¯è®­ç»ƒ**:

| ç»´åº¦ | ä¸Šä¸‹æ–‡å­¦ä¹  | ç«¯åˆ°ç«¯è®­ç»ƒ |
|:-----|:----------|:----------|
| **è¿­ä»£é€Ÿåº¦** | âš¡ å¿«é€Ÿ | ğŸŒ ç¼“æ…¢ |
| **é€‚åº”æ€§** | ğŸ¯ å¼º | âŒ å¼± |
| **å¯è§£é‡Šæ€§** | âœ… é«˜ | âŒ ä½ |
| **ç»´æŠ¤æˆæœ¬** | ğŸ’° ä½ | ğŸ’¸ é«˜ |
| **æ¨¡å‹ä¾èµ–** | ğŸš¢ éšæ¨¡å‹è¿›æ­¥è€Œæ”¹è¿› | ğŸ›ï¸ å›ºå®šåœ¨è®­ç»ƒæ—¶çŠ¶æ€ |

{: .note }
> ä¸Šä¸‹æ–‡å­¦ä¹ è®©æ™ºèƒ½ä½“åƒèˆ¹ä¸€æ ·éšç€å¤§æ¨¡å‹çš„è¿›æ­¥è€Œæå‡ï¼Œè€Œä¸æ˜¯åƒæŸ±å­ä¸€æ ·å›ºå®šä¸å˜ã€‚

---

## å…³é”®è®¾è®¡åŸåˆ™

### 1. ç¼“å­˜ä¼˜å…ˆåŸåˆ™

**æ ¸å¿ƒæ€æƒ³**: ä¿æŒ prompt å‰ç¼€ç¨³å®šï¼Œä½¿ç”¨è¿½åŠ å¼ä¸Šä¸‹æ–‡è®¾è®¡ã€‚

```python
# âŒ ä¸å¥½çš„è®¾è®¡ - ç ´åç¼“å­˜
def dynamic_prompt(task):
    return f"Current time: {time.now()}\nTask: {task}\nTools: {get_tools()}"

# âœ… å¥½çš„è®¾è®¡ - ä¿æŒç¼“å­˜
def cache_friendly_prompt(task):
    base = "You are a helpful assistant with the following tools:\n{tools_definition}"
    context = f"\n\n[New Task] {task}"
    return base + context  # è¿½åŠ è€Œéé‡å»º
```

**æ”¶ç›Š**: ç¼“å­˜ token æˆæœ¬ä»…ä¸ºæœªç¼“å­˜çš„ 1/10

### 2. é®è”½è€Œéç§»é™¤

**æ ¸å¿ƒæ€æƒ³**: ä¿ç•™æ‰€æœ‰å·¥å…·å®šä¹‰åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œé€šè¿‡ logits çº¦æŸæ§åˆ¶å¯ç”¨æ€§ã€‚

```python
# âŒ ä¸å¥½çš„è®¾è®¡ - ç ´åç¼“å­˜
def get_available_tools(state):
    if state == "search":
        return [search_tool, finish_tool]
    elif state == "analyze":
        return [analyze_tool, finish_tool]

# âœ… å¥½çš„è®¾è®¡ - å·¥å…·é®è”½
def mask_tools(state):
    all_tools = [search_tool, analyze_tool, finish_tool]  # å§‹ç»ˆå­˜åœ¨
    allowed = get_allowed_tools(state)  # åªæ§åˆ¶å¯ç”¨æ€§
    return apply_logits_mask(all_tools, allowed)
```

### 3. å¤–éƒ¨åŒ–å†…å­˜

**æ ¸å¿ƒæ€æƒ³**: æ–‡ä»¶ç³»ç»Ÿä½œä¸ºæ— é™å®¹é‡çš„æŒä¹…åŒ–å†…å­˜ã€‚

```python
# è®°å¿†ç®¡ç†
class FilesystemMemory:
    def __init__(self, workspace: Path):
        self.workspace = workspace
    
    def save(self, key: str, content: str):
        """ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        (self.workspace / f"{key}.md").write_text(content)
    
    def load(self, key: str) -> str:
        """æŒ‰éœ€åŠ è½½"""
        return (self.workspace / f"{key}.md").read_text()
    
    def summarize(self, key: str) -> str:
        """å¯æ¢å¤çš„å‹ç¼©"""
        content = self.load(key)
        summary = llm.summarize(content)
        return f"[Summary of {key}]\n{summary}\n[Load full: cat {key}.md]"
```

### 4. æ³¨æ„åŠ›å¼•å¯¼

**æ ¸å¿ƒæ€æƒ³**: é€šè¿‡è‡ªç„¶è¯­è¨€å¤è¿°æ“çºµæ³¨æ„åŠ›åˆ†å¸ƒã€‚

```python
# todo.md æœºåˆ¶
TODO_TEMPLATE = """
# Current Tasks

## High Priority
- [ ] {main_goal}

## In Progress
- [x] {completed_task}
- [ ] {current_task} <-- YOU ARE HERE

## Next Steps
1. {next_step_1}
2. {next_step_2}
"""

# æ¯è½®å¯¹è¯éƒ½å¤è¿°ç›®æ ‡
def build_context_with_attention(task, history):
    return f"""
{TODO_TEMPLATE}

Remember: Your main goal is {main_goal}
Current focus: {current_task}

{history}
"""
```

### 5. é”™è¯¯ä½œä¸ºèµ„æº

**æ ¸å¿ƒæ€æƒ³**: ä¿ç•™é”™è¯¯ä¿¡æ¯ä½œä¸ºå­¦ä¹ ææ–™ã€‚

```python
class ErrorPreservingAgent:
    def __init__(self):
        self.error_history = []
    
    def execute(self, action):
        try:
            return action.run()
        except Exception as e:
            # ä¿ç•™é”™è¯¯è€Œééšè—
            error_record = {
                'action': action,
                'error': str(e),
                'context': self.get_context(),
                'timestamp': time.now()
            }
            self.error_history.append(error_record)
            
            # ä»é”™è¯¯ä¸­å­¦ä¹ 
            self.update_beliefs(error_record)
            
            # ä¼˜é›…æ¢å¤
            return self.recover_from_error(error_record)
```

---

## ç³»ç»Ÿæ¶æ„

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[KV-Cache ä¼˜åŒ–å™¨]
    B --> C[ä¸Šä¸‹æ–‡æ„å»º]
    C --> D[å·¥å…·é€‰æ‹©]
    D --> E[ç¯å¢ƒäº¤äº’]
    E --> F[çŠ¶æ€ç®¡ç†]
    F --> G[åé¦ˆå­¦ä¹ ]
    
    C --> C1[ç¼“å­˜å‹å¥½ç»“æ„]
    C --> C2[æ³¨æ„åŠ›å¤è¿°]
    D --> D1[å·¥å…·é®è”½]
    D --> D2[çŠ¶æ€æœºæ§åˆ¶]
    E --> E1[é”™è¯¯ä¿ç•™]
    E --> E2[è§‚å¯Ÿå‹ç¼©]
    F --> F1[æ–‡ä»¶ç³»ç»Ÿå†…å­˜]
    F --> F2[è·¨ä¼šè¯æŒä¹…åŒ–]
    G --> G1[é”™è¯¯æ¨¡å¼è¯†åˆ«]
    G --> G2[ç­–ç•¥å¼ºåŒ–]
```

---

## æ€§èƒ½æŒ‡æ ‡

### ç³»ç»Ÿçº§æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|:-----|:-------|:-----|
| **KV-Cache å‘½ä¸­ç‡** | >80% | ç¼“å­˜æ•ˆç‡ |
| **å¹³å‡å“åº”æ—¶é—´** | <2s | ç«¯åˆ°ç«¯å»¶è¿Ÿ |
| **æˆæœ¬æ•ˆç‡** | 60%+ é™ä½ | ç›¸æ¯”åŸºçº¿ |

### æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ |
|:-----|:-----|
| **ä»»åŠ¡å®Œæˆç‡** | å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡æˆåŠŸç‡ |
| **ç›®æ ‡ä¸€è‡´æ€§** | é•¿æœŸä»»åŠ¡ä¸­çš„ç›®æ ‡åç¦»åº¦ |
| **é”™è¯¯æ¢å¤ç‡** | ä»å¤±è´¥ä¸­æˆåŠŸæ¢å¤çš„æ¯”ä¾‹ |
| **å­¦ä¹ é€‚åº”æ€§** | å‡å°‘é‡å¤é”™è¯¯çš„è¶‹åŠ¿ |

---

## å­¦ä¹ è·¯å¾„

### åˆçº§è·¯å¾„ (1-2 å°æ—¶)
1. Lesson 1: KV-Cache ä¼˜åŒ–
2. Lesson 2: å·¥å…·é®è”½ç­–ç•¥
3. å®ŒæˆåŸºç¡€æ€§èƒ½ä¼˜åŒ–

### ä¸­çº§è·¯å¾„ (2-3 å°æ—¶)
1. Lesson 3: æ–‡ä»¶ç³»ç»Ÿå†…å­˜
2. Lesson 4: æ³¨æ„åŠ›å¤è¿°
3. æ„å»ºæŒä¹…åŒ–æ™ºèƒ½ä½“

### é«˜çº§è·¯å¾„ (3-5 å°æ—¶)
1. Lesson 5: é”™è¯¯ä¿ç•™å­¦ä¹ 
2. é›†æˆæ‰€æœ‰æŠ€æœ¯
3. æ„å»ºç”Ÿäº§çº§æ™ºèƒ½ä½“

---

## å®éªŒç‰¹æ€§

### SSM-Agent æ¶æ„

**çŠ¶æ€ç©ºé—´æ¨¡å‹ + æ–‡ä»¶ç³»ç»Ÿå†…å­˜**:

```python
class SSMAgent:
    """åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ™ºèƒ½ä½“"""
    def __init__(self):
        self.state_model = StateSpaceModel()
        self.fs_memory = FilesystemMemory()
    
    def process(self, input_sequence):
        # ä½¿ç”¨ SSM é«˜æ•ˆå¤„ç†é•¿åºåˆ—
        compressed_state = self.state_model.encode(input_sequence)
        
        # è¯¦ç»†ä¿¡æ¯å­˜å‚¨åœ¨æ–‡ä»¶ç³»ç»Ÿ
        self.fs_memory.save("full_context", input_sequence)
        
        # åªåœ¨ä¸Šä¸‹æ–‡ä¸­ä¿ç•™å‹ç¼©çŠ¶æ€
        return compressed_state
```

### å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å·¥ç¨‹

```python
# å›¾æ–‡æ··åˆä¸Šä¸‹æ–‡ä¼˜åŒ–
def multimodal_context(text, images):
    # å›¾åƒç¼–ç ä¸ºæ–‡æœ¬æè¿°ï¼ˆå¯ç¼“å­˜ï¼‰
    image_captions = [encode_image(img) for img in images]
    
    # æ„å»ºç¼“å­˜å‹å¥½çš„ç»“æ„
    context = f"""
## Text Content
{text}

## Visual Context
{'\n'.join(image_captions)}
"""
    return context
```

---

## å®æˆ˜é¡¹ç›®

### é¡¹ç›®: ç”Ÿäº§çº§ä»»åŠ¡æ™ºèƒ½ä½“

**åŠŸèƒ½æ¸…å•**:
- âœ… ç¼“å­˜ä¼˜åŒ–çš„ prompt ç»“æ„
- âœ… çŠ¶æ€æœºé©±åŠ¨çš„å·¥å…·æ§åˆ¶
- âœ… æ–‡ä»¶ç³»ç»ŸæŒä¹…åŒ–å†…å­˜
- âœ… è‡ªåŠ¨ç›®æ ‡è·Ÿè¸ªå’Œå¤è¿°
- âœ… é”™è¯¯å­¦ä¹ å’Œä¼˜é›…æ¢å¤

**æ¶æ„ç¤ºä¾‹**:

```python
class ProductionAgent:
    def __init__(self):
        self.cache_manager = KVCacheManager()
        self.tool_masker = ToolMaskingSystem()
        self.memory = FilesystemMemory()
        self.attention = AttentionReciter()
        self.error_learner = FailureLearner()
    
    def run(self, task: str):
        # 1. ç¼“å­˜ä¼˜åŒ–
        context = self.cache_manager.build_context(task)
        
        # 2. å·¥å…·é®è”½
        available_tools = self.tool_masker.get_masked_tools(self.state)
        
        # 3. æ³¨æ„åŠ›å¼•å¯¼
        recitation = self.attention.generate_recitation(task)
        
        # 4. æ‰§è¡Œå¾ªç¯
        while not self.is_complete():
            action = self.select_action(context, available_tools, recitation)
            
            try:
                result = self.execute(action)
                self.memory.save(f"step_{self.step}", result)
            except Exception as e:
                # 5. é”™è¯¯å­¦ä¹ 
                recovery = self.error_learner.recover(e, self.get_context())
                result = recovery
        
        return self.get_final_result()
```

---

## æ‰©å±•é˜…è¯»

### å­¦æœ¯è®ºæ–‡

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Vaswani et al., 2017
- [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/abs/2309.06180) - Kwon et al., 2023
- [FlashAttention-2](https://arxiv.org/abs/2307.08691) - Dao, 2023

### æŠ€æœ¯åšå®¢

- [KV-Cache ä¼˜åŒ–å®è·µ](https://lilianweng.github.io/posts/2023-01-27-kvcache/)
- [Agent æ¶æ„è®¾è®¡æ¨¡å¼](https://developer.nvidia.com/blog/agent-architecture-patterns/)

---

## ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ å°†æŒæ¡ï¼š

1. **ç”Ÿäº§çº§æ™ºèƒ½ä½“è®¾è®¡**: æ„å»ºç¨³å®šå¯é çš„æ™ºèƒ½ä½“ç³»ç»Ÿ
2. **æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯**: æ˜¾è‘—æå‡æ™ºèƒ½ä½“æ•ˆç‡å¹¶é™ä½æˆæœ¬
3. **ä¸Šä¸‹æ–‡å·¥ç¨‹å®è·µ**: ç²¾ç»†æ§åˆ¶æ™ºèƒ½ä½“è¡Œä¸ºå’Œå†³ç­–è¿‡ç¨‹
4. **é”™è¯¯å¤„ç†å“²å­¦**: å°†å¤±è´¥è½¬åŒ–ä¸ºæ”¹è¿›æœºä¼šçš„æ€ç»´æ–¹å¼
5. **ç³»ç»Ÿæ¶æ„æ€ç»´**: å¹³è¡¡åŠŸèƒ½ã€æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§çš„è®¾è®¡èƒ½åŠ›

{: .note }
> ğŸ’¡ **é‡è¦**: ä¸Šä¸‹æ–‡å·¥ç¨‹æ˜¯å¿«é€Ÿæ¼”è¿›çš„é¢†åŸŸã€‚æœ¬ç« å†…å®¹åŸºäºå½“å‰æœ€ä½³å®è·µï¼Œå»ºè®®æŒç»­å…³æ³¨æœ€æ–°ç ”ç©¶æˆæœã€‚

